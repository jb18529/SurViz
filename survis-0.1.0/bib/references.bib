@article{kamilaris2018,
  abstract = {Deep learning (DL) constitutes a modern technique for image processing, with large potential. Having been successfully applied in various areas, it has recently also entered the domain of agriculture. In the current paper, a survey was conducted of research efforts that employ convolutional neural networks (CNN), which constitute a specific class of DL, applied to various agricultural and food production challenges. The paper examines agricultural problems under study, models employed, sources of data used and the overall precision achieved according to the performance metrics used by the authors. Convolutional neural networks are compared with other existing techniques, and the advantages and disadvantages of using CNN in agriculture are listed. Moreover, the future potential of this technique is discussed, together with the authors’ personal experiences after employing CNN to approximate a problem of identifying missing vegetation from a sugar cane plantation in Costa Rica. The overall findings indicate that CNN constitutes a promising technique with high performance in terms of precision and classification accuracy, outperforming existing commonly used image-processing techniques. However, the success of each CNN model is highly dependent on the quality of the data set used.}, 
  author = {Kamilaris, A. and Prenafeta-Boldú, F. X},
  doi = {10.1017/S0021859618000436},
  journal = {The Journal of Agricultural Science},
  keywords = {type: agriculuture, convolutional_neural_networks, deep_learning, smart_farming, survey},
  number = {01},
  publisher = {Cambridge University Press},
  series = {Crop and Soils Review},
  title = {A review of the use of convolutional neural networks in agriculture},
  url = {https://www.cambridge.org/core/journals/journal-of-agricultural-science/article/review-of-the-use-of-convolutional-neural-networks-in-agriculture/15B08C5CDD85F21EEEFAFE7387536149},
  volume = {156},
  year = {2018}
}
@article{krizhevsky2018,
  abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5 and 17.0, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3, compared to 26.2 achieved by the second-best entry.}, 
  author = {Krizhevsky, A., Sutskever, I. and Hinton, G.E},
  doi = {10.1145/3065386},
  journal = {Communications of the ACM},
  keywords = {type: N/A},
  number = {02},
  publisher = {Association for Computing Machinery},
  series = {N/A},
  title = { Imagenet classification with deep convolutional neural networks},
  url = {https://dl.acm.org/doi/abs/10.1145/3065386},
  volume = {60},
  year = {2018}
}
@article{Hiary2018,
  abstract = {Flower classification is a challenging task due to the wide range of flower species, which have a similar shape, appearance or surrounding objects such as leaves and grass. In this study, the authors propose a novel two-step deep learning classifier to distinguish flowers of a wide range of species. First, the flower region is automatically segmented to allow localisation of the minimum bounding box around it. The proposed flower segmentation approach is modelled as a binary classifier in a fully convolutional network framework. Second, they build a robust convolutional neural network classifier to distinguish the different flower types. They propose novel steps during the training stage to ensure robust, accurate and real-time classification. They evaluate their method on three well known flower datasets. Their classification results exceed 97 percent on all datasets, which are better than the state-of-the-art in this domain.}, 
  author = {Hiary, H., Saadeh, H., Saadeh, M. and Yaqub, M},
  doi = {10.1049/iet-cvi.2017.0155},
  journal = {IET Computer Vision},
  keywords = {type: biology_computing, botany, feedforward_neural_nets, learning, pattern_classification, object_recognition, flower_classification, deep_convolutional_neural_networks, flower_species, two_step_deep_learning_classifier, robust_convolutional_neural_network_classifier, training_stage},
  number = {03},
  publisher = {IET Computer Vision},
  series = {N/A},
  title = {Flower classification using deep convolutional neural networks},
  url = {https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-cvi.2017.0155},
  volume = {12},
  year = {2018}
} 
@article{Liu2016,
  abstract = {In this paper, we address the problem of natural flower classification. It is a challenging task due to the non-rigid deformation, illumination changes, and inter-class similarity. We build a large dataset of flower images in the wide with 79 categories and propose a novel framework based on convolutional neural network (CNN) to solve this problem. Unlike other methods using hand-crafted visual features, our method utilizes convolutional neural network to automatically learn good features for flower classification. The neural network consists of five convolutional layers where small receptive fields are adopted, some of which are followed by max-pooling layers, and three fully-connected layers with a final 79-way softmax. Our approach achieves 76.54 percent classification accuracy on our challenging flower dataset. Moreover, test our algorithm on the Oxford 102 Flowers dataset. It outperforms the previous known methods and achieves 84.02 percent  classification accuracy. Experimental results on a well-known dataset and our own dataset demonstrate that our method is quite effective in flower classification.}, 
  author = {Liu, Y., Tang, F., Zhou, D., Meng, Y. and Dong, W},
  doi = {10.1109/FSPMA.2016.7818296},
  journal = {IEEE International Conference on Functional-Structural Plant Growth Modeling, Simulation, Visualization and Applications (FSPMA)},
  keywords = {type: flower_classification, convolutional_neural_network},
  number = {04},
  publisher = {IEEE},
  series = {FSPMA},
  title = {Flower classification via convolutional neural network},
  url = {https://ieeexplore.ieee.org/document/7818296},
  volume = {N/A},
  year = {2016}
}
@article{Xia2017,
  abstract = {The study of flower classification system is a very important subject in the field of Botany. A classifier of flowers with high accuracy will also bring a lot of fun to people's lives. However, because of the complex background of flowers, the similarity between the different species of flowers, and the differences among the same species of flowers, there are still some challenges in the recognition of flower images. The traditional flower classification is mainly based on the three features: color, shape and texture, this classification requires people to select features for classification, and the accuracy is not very high. In this paper, based on Inception-v3 model of TensorFlow platform, we use the transfer learning technology to retrain the flower category datasets, which can greatly improve the accuracy of flower classification.}, 
  author = {Xia, X., Xu, C. and Nan, B},
  doi = {10.1109/ICIVC.2017.7984661},
  journal = {2017 2nd international conference on image, vision and computing (ICIVC)},
  keywords = {type: flower_classification, TensorFlow, inception-v3, transfer_learning},
  number = {05},
  publisher = {IEEE},
  series = {ICIVC},
  title = {Inception-v3 for flower classification},
  url = {https://ieeexplore.ieee.org/document/7984661},
  volume = {N/A},
  year = {2017}
}
@article{Gavai2017,
  abstract = {Classification of objects into their specific classes is always been significant tasks of machine learning. As the study of flower, categorizing specific class of flower is important subject in the field of Botany but the similarity between the diverse species of flowers, texture and color of flowers, and the dissimilarities amongst the same species of flowers, there still are some challenges in the recognition of flower images. Existing recent Google's inception-v3 model comparatively takes more time and space for classification with high accuracy. In this paper, we have shown experimental performance of MobileNets model on TensorFlow platform to retrain the flower category datasets, which can greatly minimize the time and space for flower classification compromising the accuracy slightly.}, 
  author = {Gavai, N.R., Jakhade, Y.A., Tribhuvan, S.A. and Bhattad},
  doi = {10.1109/BID.2017.8336590},
  journal = {2017 international conference on big data, IoT and data science (BID)},
  keywords = {type: classification, TensorFlow, inception-v3, Mobile_Nets},
  number = {06},
  publisher = {IEEE},
  series = {BID},
  title = {MobileNets for flower classification using TensorFlow},
  url = {https://ieeexplore.ieee.org/document/8336590},
  volume = {N/A},
  year = {2017}
}
@article{Sun2017,
  abstract = {Flower grading is a significant task because it is extremely convenient for managing the flowers in greenhouse and market. With the development of computer vision, flower grading has become an interdisciplinary focus in both botany and computer vision. A new dataset named BjfuGloxinia contains three quality grades; each grade consists of 107 samples and 321 images. A multi-input convolutional neural network is designed for large scale flower grading. Multi-input CNN achieves a satisfactory accuracy of 89.6 percent on the BjfuGloxinia after data augmentation. Compared with a single-input CNN, the accuracy of multi-input CNN is increased by 5 percent on average, demonstrating that multi-input convolutional neural network is a promising model for flower grading. Although data augmentation contributes to the model, the accuracy is still limited by lack of samples diversity. Majority of misclassification is derived from the medium class. The image processing based bud detection is useful for reducing the misclassification, increasing the accuracy of flower grading to approximately 93.9 percent.}, 
  author = {Sun, Y., Zhu, L., Wang, G. and Zhao, F},
  doi = {10.1155/2017/9240407},
  journal = {Journal of Electrical and Computer Engineering},
  keywords = {type: multi_input_convolutional_neural_network, flower_grading},
  number = {07},
  publisher = {Hindawi},
  series = {N/A},
  title = { Multi-input convolutional neural network for flower grading},
  url = {https://www.hindawi.com/journals/jece/2017/9240407/},
  volume = {N/A},
  year = {2017}
}
@article{Wu2018,
  abstract = {Flower plays an extremely important role in our life, which has high research value and application value. The traditional methods of flower classification is mainly based on shape, color or texture features, and this methods needs people to select features for flower classification lead to the accuracy of classification is not very high. This paper aims to develop an effective flower classification approach using convolution neural network and transfer learning. In this paper, based on VGG-16, VGG-19, Inception-v3 and ResNet50 models were used to compare the network initialization model with the transfer learning model. The results show that transfer learning can effectively avoid deep convolution networks are prone to local optimal problems and over-fitting problems. Compared with the traditional methods, the accuracy of flower recognition on Oxford flowers dataset is obviously improved, and has better robustness and generalization ability.}, 
  author = {Wu, Y., Qin, X., Pan, Y. and Yuan, C},
  doi = {10.1109/SIPROCESS.2018.8600536},
  journal = {2018 IEEE 3rd international conference on signal and image processing (ICSIP)},
  keywords = {type: deep_learning, convolutional_neural_network, transfer_learning, flowers_classification},
  number = {08},
  publisher = {IEEE},
  series = {ICSIP},
  title = {Convolution neural network based transfer learning for classification of flowers},
  url = {https://ieeexplore.ieee.org/document/8600536},
  volume = {N/A},
  year = {2018}
}
@article{Toğaçar2020,
  abstract = {It is important for the sensitivity of ecological balance that image processing methods and techniques give better results day by day. Today, researchers use deep learning in image-based object recognition. Recently, the use of deep learning methods on plant species has increased. In this study, a hybrid method that is used together with feature selection methods and Convolutional Neural Network (CNN) models is presented. In the proposed model, CNN models are used for feature extraction. The features obtained from these models are combined and efficient features are selected with feature selection methods. The aim here is to subtract and classify intersecting features between the features obtained by feature selection methods. When the results of the experiments are compared, the intersection of the features obtained by feature selection methods are contributed to the classification performance. The classification success achieved by the Support Vector Machine (SVM) method was 98.91 percent.}, 
  author = {Toğaçar, M., Ergen, B. and Cömert, Z},
  doi = {10.1016/j.measurement.2020.107703},
  journal = {Measurement},
  keywords = {type: deep_learning, flower_species, feature_selection, feature_intersection},
  number = {09},
  publisher = {Elsevier},
  series = {N/A},
  title = {Classification of flower species by using features extracted from the intersection of feature selection methods in convolutional neural network models},
  url = {https://www.sciencedirect.com/science/article/pii/S0263224120302414#kg005},
  volume = {158},
  year = {2020}
}
@article{Bae2020,
  abstract = {The new multi-view learning algorithm is proposed by modifying an existing method, the multimodal convolutional neural networks originally developed for image-text matching (modified m-CNN), to use not only images but also texts for classification. Firstly, pre-trained CNN and word embedding models are applied to extract visual features and represent each word in a text as a vector, respectively. Secondly, textual features are extracted by employing a CNN model for text data. Finally, pairs of features extracted through the text and image CNNs are concatenated and input to convolutional layer which can obtain a better learn of the important feature information in the integrated representation of image and text. Features extracted from the convolutional layer are input to a fully connected layer to perform classification. Experimental results demonstrate that the proposed algorithm can obtain superior performance compared with other data fusion methods for flower classification using data of images of flowers and their Korean descriptions. More specifically, the accuracy of the proposed algorithm is 10.1 percent and 14.5 percent higher than m-CNN and multimodal recurrent neural networks algorithms, respectively. The proposed method can significantly improve the performance of flower classification. The code and related data are publicly available via our GitHub repository.}, 
  author = {Bae, K.I., Park, J., Lee, J., Lee, Y. and Lim, C},
  doi = {10.1016/j.eswa.2020.113455},
  journal = {Expert Systems with Applications},
  keywords = {type: deep_learning, multi_view_learning, image, data_fusion, classification},
  number = {10},
  publisher = {Elsevier},
  series = {N/A},
  title = {Flower classification with modified multimodal convolutional neural networks},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417420302797},
  volume = {159},
  year = {2020}
}

